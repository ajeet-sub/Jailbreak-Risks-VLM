{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1875,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 1.7337087392807007,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 4.9759,
      "step": 10
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.925450325012207,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 5.0313,
      "step": 20
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.192373037338257,
      "learning_rate": 5.8e-06,
      "loss": 5.0207,
      "step": 30
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.7319953441619873,
      "learning_rate": 7.800000000000002e-06,
      "loss": 4.878,
      "step": 40
    },
    {
      "epoch": 0.08,
      "grad_norm": 2.9011223316192627,
      "learning_rate": 9.800000000000001e-06,
      "loss": 4.6906,
      "step": 50
    },
    {
      "epoch": 0.096,
      "grad_norm": 3.6406614780426025,
      "learning_rate": 1.18e-05,
      "loss": 4.2759,
      "step": 60
    },
    {
      "epoch": 0.112,
      "grad_norm": 2.977108955383301,
      "learning_rate": 1.38e-05,
      "loss": 3.744,
      "step": 70
    },
    {
      "epoch": 0.128,
      "grad_norm": 3.1786623001098633,
      "learning_rate": 1.58e-05,
      "loss": 3.1999,
      "step": 80
    },
    {
      "epoch": 0.144,
      "grad_norm": 2.805663585662842,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 2.4788,
      "step": 90
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.184882402420044,
      "learning_rate": 1.98e-05,
      "loss": 1.7153,
      "step": 100
    },
    {
      "epoch": 0.176,
      "grad_norm": 1.4425268173217773,
      "learning_rate": 1.9898591549295776e-05,
      "loss": 1.137,
      "step": 110
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.5620806217193604,
      "learning_rate": 1.9785915492957747e-05,
      "loss": 0.9688,
      "step": 120
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.4360905587673187,
      "learning_rate": 1.967323943661972e-05,
      "loss": 0.9561,
      "step": 130
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.4109083414077759,
      "learning_rate": 1.9560563380281692e-05,
      "loss": 0.8817,
      "step": 140
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4548046588897705,
      "learning_rate": 1.9447887323943663e-05,
      "loss": 0.9295,
      "step": 150
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.511733889579773,
      "learning_rate": 1.9335211267605637e-05,
      "loss": 0.8813,
      "step": 160
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.7172971963882446,
      "learning_rate": 1.922253521126761e-05,
      "loss": 0.8587,
      "step": 170
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.4002637565135956,
      "learning_rate": 1.910985915492958e-05,
      "loss": 0.8811,
      "step": 180
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.3426579535007477,
      "learning_rate": 1.899718309859155e-05,
      "loss": 0.8351,
      "step": 190
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4162234663963318,
      "learning_rate": 1.8884507042253525e-05,
      "loss": 0.8521,
      "step": 200
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3924066424369812,
      "learning_rate": 1.8771830985915492e-05,
      "loss": 0.9192,
      "step": 210
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.3776710629463196,
      "learning_rate": 1.8659154929577467e-05,
      "loss": 0.8102,
      "step": 220
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.3821525275707245,
      "learning_rate": 1.8546478873239438e-05,
      "loss": 0.8395,
      "step": 230
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.4563091993331909,
      "learning_rate": 1.843380281690141e-05,
      "loss": 0.8582,
      "step": 240
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.3910626769065857,
      "learning_rate": 1.832112676056338e-05,
      "loss": 0.8492,
      "step": 250
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.5043221712112427,
      "learning_rate": 1.8208450704225354e-05,
      "loss": 0.8425,
      "step": 260
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.40629449486732483,
      "learning_rate": 1.8095774647887325e-05,
      "loss": 0.8348,
      "step": 270
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.41337862610816956,
      "learning_rate": 1.7983098591549296e-05,
      "loss": 0.8617,
      "step": 280
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.43395107984542847,
      "learning_rate": 1.787042253521127e-05,
      "loss": 0.8565,
      "step": 290
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.45327499508857727,
      "learning_rate": 1.775774647887324e-05,
      "loss": 0.8258,
      "step": 300
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.38857412338256836,
      "learning_rate": 1.7645070422535212e-05,
      "loss": 0.8232,
      "step": 310
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.40987280011177063,
      "learning_rate": 1.7532394366197183e-05,
      "loss": 0.8613,
      "step": 320
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.4902481138706207,
      "learning_rate": 1.7419718309859158e-05,
      "loss": 0.8706,
      "step": 330
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.37370795011520386,
      "learning_rate": 1.730704225352113e-05,
      "loss": 0.8201,
      "step": 340
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40208959579467773,
      "learning_rate": 1.71943661971831e-05,
      "loss": 0.8598,
      "step": 350
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.442674845457077,
      "learning_rate": 1.708169014084507e-05,
      "loss": 0.8456,
      "step": 360
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.4852125346660614,
      "learning_rate": 1.6969014084507042e-05,
      "loss": 0.8713,
      "step": 370
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.4465261697769165,
      "learning_rate": 1.6856338028169016e-05,
      "loss": 0.8622,
      "step": 380
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.5038866400718689,
      "learning_rate": 1.6743661971830987e-05,
      "loss": 0.8336,
      "step": 390
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.5224418640136719,
      "learning_rate": 1.6630985915492958e-05,
      "loss": 0.8284,
      "step": 400
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.42503246665000916,
      "learning_rate": 1.651830985915493e-05,
      "loss": 0.7968,
      "step": 410
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.48628902435302734,
      "learning_rate": 1.6405633802816904e-05,
      "loss": 0.8309,
      "step": 420
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.5076764225959778,
      "learning_rate": 1.6292957746478875e-05,
      "loss": 0.8262,
      "step": 430
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.512482762336731,
      "learning_rate": 1.6180281690140846e-05,
      "loss": 0.8477,
      "step": 440
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3285232186317444,
      "learning_rate": 1.606760563380282e-05,
      "loss": 0.8151,
      "step": 450
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.4567198157310486,
      "learning_rate": 1.595492957746479e-05,
      "loss": 0.8358,
      "step": 460
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.5127221345901489,
      "learning_rate": 1.5842253521126762e-05,
      "loss": 0.8552,
      "step": 470
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.42430758476257324,
      "learning_rate": 1.5729577464788733e-05,
      "loss": 0.8284,
      "step": 480
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.44415152072906494,
      "learning_rate": 1.5616901408450707e-05,
      "loss": 0.8967,
      "step": 490
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4543587267398834,
      "learning_rate": 1.550422535211268e-05,
      "loss": 0.8503,
      "step": 500
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.40740564465522766,
      "learning_rate": 1.539154929577465e-05,
      "loss": 0.8426,
      "step": 510
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.39688095450401306,
      "learning_rate": 1.527887323943662e-05,
      "loss": 0.8277,
      "step": 520
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.5189105868339539,
      "learning_rate": 1.5166197183098591e-05,
      "loss": 0.8315,
      "step": 530
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.4618860185146332,
      "learning_rate": 1.5053521126760564e-05,
      "loss": 0.8573,
      "step": 540
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.41328760981559753,
      "learning_rate": 1.4940845070422537e-05,
      "loss": 0.8415,
      "step": 550
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.5078596472740173,
      "learning_rate": 1.4828169014084508e-05,
      "loss": 0.8178,
      "step": 560
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.4384218752384186,
      "learning_rate": 1.471549295774648e-05,
      "loss": 0.8606,
      "step": 570
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.49043095111846924,
      "learning_rate": 1.4602816901408452e-05,
      "loss": 0.8137,
      "step": 580
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.6975319385528564,
      "learning_rate": 1.4490140845070424e-05,
      "loss": 0.894,
      "step": 590
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4049096405506134,
      "learning_rate": 1.4377464788732395e-05,
      "loss": 0.7884,
      "step": 600
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.47166189551353455,
      "learning_rate": 1.4264788732394368e-05,
      "loss": 0.8132,
      "step": 610
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.4705716073513031,
      "learning_rate": 1.415211267605634e-05,
      "loss": 0.8056,
      "step": 620
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.5291146039962769,
      "learning_rate": 1.4039436619718312e-05,
      "loss": 0.859,
      "step": 630
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.4180690348148346,
      "learning_rate": 1.3926760563380284e-05,
      "loss": 0.8501,
      "step": 640
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.47639310359954834,
      "learning_rate": 1.3814084507042254e-05,
      "loss": 0.861,
      "step": 650
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.39422935247421265,
      "learning_rate": 1.3701408450704226e-05,
      "loss": 0.8385,
      "step": 660
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.4245215058326721,
      "learning_rate": 1.3588732394366197e-05,
      "loss": 0.83,
      "step": 670
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.46451130509376526,
      "learning_rate": 1.347605633802817e-05,
      "loss": 0.8003,
      "step": 680
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.43488678336143494,
      "learning_rate": 1.3363380281690141e-05,
      "loss": 0.8269,
      "step": 690
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.40465879440307617,
      "learning_rate": 1.3250704225352114e-05,
      "loss": 0.8131,
      "step": 700
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.44799214601516724,
      "learning_rate": 1.3138028169014085e-05,
      "loss": 0.8615,
      "step": 710
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.45217248797416687,
      "learning_rate": 1.3025352112676057e-05,
      "loss": 0.8656,
      "step": 720
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.5231820940971375,
      "learning_rate": 1.291267605633803e-05,
      "loss": 0.816,
      "step": 730
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.470885694026947,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.8269,
      "step": 740
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.49568209052085876,
      "learning_rate": 1.2687323943661974e-05,
      "loss": 0.8251,
      "step": 750
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.47628676891326904,
      "learning_rate": 1.2574647887323945e-05,
      "loss": 0.7838,
      "step": 760
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.4749767482280731,
      "learning_rate": 1.2461971830985918e-05,
      "loss": 0.889,
      "step": 770
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.43876004219055176,
      "learning_rate": 1.2349295774647889e-05,
      "loss": 0.7835,
      "step": 780
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.6539139747619629,
      "learning_rate": 1.2236619718309861e-05,
      "loss": 0.8715,
      "step": 790
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5221101641654968,
      "learning_rate": 1.212394366197183e-05,
      "loss": 0.8496,
      "step": 800
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.4037446975708008,
      "learning_rate": 1.2011267605633803e-05,
      "loss": 0.8034,
      "step": 810
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.4723077714443207,
      "learning_rate": 1.1898591549295774e-05,
      "loss": 0.7767,
      "step": 820
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.4486830532550812,
      "learning_rate": 1.1785915492957747e-05,
      "loss": 0.9269,
      "step": 830
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.5639402270317078,
      "learning_rate": 1.167323943661972e-05,
      "loss": 0.7697,
      "step": 840
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.4424552917480469,
      "learning_rate": 1.156056338028169e-05,
      "loss": 0.8304,
      "step": 850
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.43329158425331116,
      "learning_rate": 1.1447887323943663e-05,
      "loss": 0.8547,
      "step": 860
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.46457189321517944,
      "learning_rate": 1.1335211267605634e-05,
      "loss": 0.8459,
      "step": 870
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.4856642186641693,
      "learning_rate": 1.1222535211267607e-05,
      "loss": 0.8197,
      "step": 880
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.5099976658821106,
      "learning_rate": 1.1109859154929578e-05,
      "loss": 0.8567,
      "step": 890
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.45288485288619995,
      "learning_rate": 1.099718309859155e-05,
      "loss": 0.8389,
      "step": 900
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.4306226670742035,
      "learning_rate": 1.0884507042253523e-05,
      "loss": 0.8448,
      "step": 910
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.48083898425102234,
      "learning_rate": 1.0771830985915494e-05,
      "loss": 0.8523,
      "step": 920
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.4756677448749542,
      "learning_rate": 1.0659154929577467e-05,
      "loss": 0.8687,
      "step": 930
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.4912711977958679,
      "learning_rate": 1.0546478873239438e-05,
      "loss": 0.8092,
      "step": 940
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.4878312349319458,
      "learning_rate": 1.0433802816901409e-05,
      "loss": 0.788,
      "step": 950
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.4991605877876282,
      "learning_rate": 1.032112676056338e-05,
      "loss": 0.8211,
      "step": 960
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.49628961086273193,
      "learning_rate": 1.0208450704225353e-05,
      "loss": 0.856,
      "step": 970
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.5972018837928772,
      "learning_rate": 1.0095774647887324e-05,
      "loss": 0.8044,
      "step": 980
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.6124283075332642,
      "learning_rate": 9.983098591549296e-06,
      "loss": 0.8853,
      "step": 990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.4460633397102356,
      "learning_rate": 9.870422535211267e-06,
      "loss": 0.8208,
      "step": 1000
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.4838603734970093,
      "learning_rate": 9.75774647887324e-06,
      "loss": 0.8407,
      "step": 1010
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.46749165654182434,
      "learning_rate": 9.645070422535213e-06,
      "loss": 0.8645,
      "step": 1020
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.5746117234230042,
      "learning_rate": 9.532394366197184e-06,
      "loss": 0.8533,
      "step": 1030
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.46785983443260193,
      "learning_rate": 9.419718309859157e-06,
      "loss": 0.808,
      "step": 1040
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.4866902232170105,
      "learning_rate": 9.307042253521128e-06,
      "loss": 0.7955,
      "step": 1050
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.5241698026657104,
      "learning_rate": 9.194366197183099e-06,
      "loss": 0.8237,
      "step": 1060
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.5900244116783142,
      "learning_rate": 9.081690140845071e-06,
      "loss": 0.8204,
      "step": 1070
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.5388079881668091,
      "learning_rate": 8.969014084507042e-06,
      "loss": 0.827,
      "step": 1080
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.5074834823608398,
      "learning_rate": 8.856338028169015e-06,
      "loss": 0.8296,
      "step": 1090
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.4456496834754944,
      "learning_rate": 8.743661971830986e-06,
      "loss": 0.7911,
      "step": 1100
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.500887393951416,
      "learning_rate": 8.630985915492959e-06,
      "loss": 0.8046,
      "step": 1110
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.4936893880367279,
      "learning_rate": 8.518309859154931e-06,
      "loss": 0.8132,
      "step": 1120
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.5000629425048828,
      "learning_rate": 8.405633802816902e-06,
      "loss": 0.837,
      "step": 1130
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.4802023768424988,
      "learning_rate": 8.292957746478873e-06,
      "loss": 0.7952,
      "step": 1140
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.5560135841369629,
      "learning_rate": 8.180281690140846e-06,
      "loss": 0.8162,
      "step": 1150
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.4504578113555908,
      "learning_rate": 8.067605633802817e-06,
      "loss": 0.8081,
      "step": 1160
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.6064550280570984,
      "learning_rate": 7.95492957746479e-06,
      "loss": 0.8106,
      "step": 1170
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.5176623463630676,
      "learning_rate": 7.84225352112676e-06,
      "loss": 0.8444,
      "step": 1180
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.4865444302558899,
      "learning_rate": 7.729577464788733e-06,
      "loss": 0.7898,
      "step": 1190
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.4913190007209778,
      "learning_rate": 7.616901408450705e-06,
      "loss": 0.784,
      "step": 1200
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.44387057423591614,
      "learning_rate": 7.504225352112676e-06,
      "loss": 0.8282,
      "step": 1210
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.5390827655792236,
      "learning_rate": 7.391549295774648e-06,
      "loss": 0.8249,
      "step": 1220
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.5211879014968872,
      "learning_rate": 7.27887323943662e-06,
      "loss": 0.8516,
      "step": 1230
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.45220357179641724,
      "learning_rate": 7.166197183098592e-06,
      "loss": 0.8327,
      "step": 1240
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.46662425994873047,
      "learning_rate": 7.0535211267605645e-06,
      "loss": 0.8082,
      "step": 1250
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.5334957242012024,
      "learning_rate": 6.940845070422536e-06,
      "loss": 0.8392,
      "step": 1260
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.5359209179878235,
      "learning_rate": 6.828169014084508e-06,
      "loss": 0.8601,
      "step": 1270
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.6235455870628357,
      "learning_rate": 6.715492957746479e-06,
      "loss": 0.8143,
      "step": 1280
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.4819597601890564,
      "learning_rate": 6.602816901408451e-06,
      "loss": 0.8439,
      "step": 1290
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5353372097015381,
      "learning_rate": 6.490140845070423e-06,
      "loss": 0.8188,
      "step": 1300
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.6330451369285583,
      "learning_rate": 6.377464788732395e-06,
      "loss": 0.814,
      "step": 1310
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.538038969039917,
      "learning_rate": 6.264788732394367e-06,
      "loss": 0.8561,
      "step": 1320
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.5262723565101624,
      "learning_rate": 6.1521126760563385e-06,
      "loss": 0.8496,
      "step": 1330
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.5082895755767822,
      "learning_rate": 6.039436619718311e-06,
      "loss": 0.8323,
      "step": 1340
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.5238769054412842,
      "learning_rate": 5.926760563380283e-06,
      "loss": 0.8268,
      "step": 1350
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.49605023860931396,
      "learning_rate": 5.814084507042254e-06,
      "loss": 0.7925,
      "step": 1360
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.5021752715110779,
      "learning_rate": 5.701408450704226e-06,
      "loss": 0.8001,
      "step": 1370
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.5442757606506348,
      "learning_rate": 5.588732394366198e-06,
      "loss": 0.8255,
      "step": 1380
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.6794203519821167,
      "learning_rate": 5.4760563380281695e-06,
      "loss": 0.8279,
      "step": 1390
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6115758419036865,
      "learning_rate": 5.363380281690141e-06,
      "loss": 0.8516,
      "step": 1400
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.5792948007583618,
      "learning_rate": 5.250704225352113e-06,
      "loss": 0.7952,
      "step": 1410
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.5162596702575684,
      "learning_rate": 5.138028169014085e-06,
      "loss": 0.7828,
      "step": 1420
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.5238576531410217,
      "learning_rate": 5.025352112676056e-06,
      "loss": 0.8111,
      "step": 1430
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.47157058119773865,
      "learning_rate": 4.912676056338029e-06,
      "loss": 0.7938,
      "step": 1440
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5286075472831726,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.8261,
      "step": 1450
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.5741204023361206,
      "learning_rate": 4.6873239436619725e-06,
      "loss": 0.807,
      "step": 1460
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.639727771282196,
      "learning_rate": 4.574647887323944e-06,
      "loss": 0.8167,
      "step": 1470
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.524692952632904,
      "learning_rate": 4.461971830985916e-06,
      "loss": 0.8557,
      "step": 1480
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.5817862153053284,
      "learning_rate": 4.349295774647887e-06,
      "loss": 0.8136,
      "step": 1490
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5288062691688538,
      "learning_rate": 4.23661971830986e-06,
      "loss": 0.8693,
      "step": 1500
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.618079662322998,
      "learning_rate": 4.123943661971832e-06,
      "loss": 0.8648,
      "step": 1510
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.5669927000999451,
      "learning_rate": 4.011267605633803e-06,
      "loss": 0.8164,
      "step": 1520
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.48841848969459534,
      "learning_rate": 3.8985915492957746e-06,
      "loss": 0.7781,
      "step": 1530
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.5208715200424194,
      "learning_rate": 3.785915492957747e-06,
      "loss": 0.8029,
      "step": 1540
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5649707317352295,
      "learning_rate": 3.6732394366197187e-06,
      "loss": 0.8078,
      "step": 1550
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.6831706166267395,
      "learning_rate": 3.56056338028169e-06,
      "loss": 0.8151,
      "step": 1560
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.6115174889564514,
      "learning_rate": 3.4478873239436624e-06,
      "loss": 0.8396,
      "step": 1570
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.5853195786476135,
      "learning_rate": 3.3352112676056342e-06,
      "loss": 0.8461,
      "step": 1580
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.4825884997844696,
      "learning_rate": 3.222535211267606e-06,
      "loss": 0.8067,
      "step": 1590
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.6161709427833557,
      "learning_rate": 3.1098591549295775e-06,
      "loss": 0.7901,
      "step": 1600
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.5624099373817444,
      "learning_rate": 2.9971830985915494e-06,
      "loss": 0.8082,
      "step": 1610
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.545968234539032,
      "learning_rate": 2.8845070422535216e-06,
      "loss": 0.8063,
      "step": 1620
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.6029179692268372,
      "learning_rate": 2.771830985915493e-06,
      "loss": 0.8248,
      "step": 1630
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.593079686164856,
      "learning_rate": 2.659154929577465e-06,
      "loss": 0.8289,
      "step": 1640
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6309548616409302,
      "learning_rate": 2.5464788732394367e-06,
      "loss": 0.8507,
      "step": 1650
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.6216169595718384,
      "learning_rate": 2.4338028169014086e-06,
      "loss": 0.8083,
      "step": 1660
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.5841907858848572,
      "learning_rate": 2.3211267605633804e-06,
      "loss": 0.8107,
      "step": 1670
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.604901134967804,
      "learning_rate": 2.2084507042253523e-06,
      "loss": 0.7826,
      "step": 1680
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.6208388805389404,
      "learning_rate": 2.095774647887324e-06,
      "loss": 0.7951,
      "step": 1690
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.5604493021965027,
      "learning_rate": 1.983098591549296e-06,
      "loss": 0.8177,
      "step": 1700
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.5556850433349609,
      "learning_rate": 1.8704225352112678e-06,
      "loss": 0.8263,
      "step": 1710
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.5236336588859558,
      "learning_rate": 1.7577464788732395e-06,
      "loss": 0.8591,
      "step": 1720
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.7080960273742676,
      "learning_rate": 1.6450704225352113e-06,
      "loss": 0.8609,
      "step": 1730
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.6206705570220947,
      "learning_rate": 1.5323943661971832e-06,
      "loss": 0.8626,
      "step": 1740
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.5664638876914978,
      "learning_rate": 1.419718309859155e-06,
      "loss": 0.7809,
      "step": 1750
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.5985948443412781,
      "learning_rate": 1.3070422535211269e-06,
      "loss": 0.7767,
      "step": 1760
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.5112813115119934,
      "learning_rate": 1.1943661971830987e-06,
      "loss": 0.8487,
      "step": 1770
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.6697467565536499,
      "learning_rate": 1.0816901408450706e-06,
      "loss": 0.8116,
      "step": 1780
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.5510437488555908,
      "learning_rate": 9.690140845070424e-07,
      "loss": 0.8306,
      "step": 1790
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5778899788856506,
      "learning_rate": 8.563380281690141e-07,
      "loss": 0.8481,
      "step": 1800
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.5174990892410278,
      "learning_rate": 7.436619718309859e-07,
      "loss": 0.7623,
      "step": 1810
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.5578406453132629,
      "learning_rate": 6.309859154929577e-07,
      "loss": 0.7962,
      "step": 1820
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.6175870299339294,
      "learning_rate": 5.183098591549296e-07,
      "loss": 0.7996,
      "step": 1830
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.6030696034431458,
      "learning_rate": 4.0563380281690143e-07,
      "loss": 0.8008,
      "step": 1840
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.6151921153068542,
      "learning_rate": 2.929577464788733e-07,
      "loss": 0.8341,
      "step": 1850
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.5001188516616821,
      "learning_rate": 1.802816901408451e-07,
      "loss": 0.8114,
      "step": 1860
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.563739001750946,
      "learning_rate": 6.760563380281691e-08,
      "loss": 0.7773,
      "step": 1870
    }
  ],
  "logging_steps": 10,
  "max_steps": 1875,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.612545732126659e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
